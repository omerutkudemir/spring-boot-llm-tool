# ğŸƒ Spring Boot AI Assistant (Hybrid: RAG + Fine-Tuning)


> **Language Selection / Dil SeÃ§imi:**
>
> [ğŸ‡¬ğŸ‡§ **English Documentation**](#-english-documentation)
>
> [ğŸ‡¹ğŸ‡· **TÃ¼rkÃ§e DokÃ¼mantasyon**](#-tÃ¼rkÃ§e-dokÃ¼mantasyon)

---

<a name="-english-documentation"></a>
# ğŸ‡¬ğŸ‡§ English Documentation

This project is an advanced AI assistant specialized for the **Spring Boot** ecosystem, combining **RAG (Retrieval-Augmented Generation)** and **Fine-Tuning** techniques.

Built to run on **Google Colab T4 GPU** using the **Unsloth** optimization framework, it utilizes the **Meta-Llama-3.1-8B-Instruct** model. It delivers both precise information retrieval based on documentation (RAG) and internalized domain expertise (Fine-Tuning).

## ğŸš€ About the Project & Development Process

Unlike standard chatbots, this system is built on a custom data pipeline derived from raw documentation processing:

1.  **Data Processing (Llama Parse):** The development process began by parsing the official **Spring Boot PDF documentation**. The **Llama Parse** library was used to transform complex PDF structures (tables, headers) into machine-readable, structured Markdown/JSON.
2.  **Dataset Generation (OpenAI API):** To transform the model from a simple "reader" into an "expert," the parsed documents were processed via the **OpenAI API**. High-quality **Question-Answer pairs** were generated to create a structured JSON **Fine-Tuning dataset**.
3.  **Hybrid Architecture (RAG + FT):**
    * **RAG (Knowledge Base):** The parsed content acts as a vector-based knowledge base for real-time retrieval.
    * **Fine-Tuning (Expertise):** The Llama 3.1 8B model was fine-tuned on **Colab T4** using the Q&A pairs to deeply understand Spring Boot concepts and coding standards.

## âš¡ Features

* **T4 GPU Optimization:** Thanks to Unsloth and 4-bit quantization, the entire system runs smoothly on the free Colab T4 GPU.
* **Smart Translation Agent:** Automatically translates non-English queries into English in the background to improve RAG retrieval accuracy while preserving technical terminology.
* **Web Interface:** Features a modern, ChatGPT-like interface with syntax highlighting.
* **Public Access:** Exposes the local Colab server to the internet via Ngrok tunneling.

## ğŸ› ï¸ Installation & Usage on Colab

### 1. Required Files
Upload the following two files to the file manager in the left sidebar of Google Colab:
* `spring_boot_finetune_full.jsonl`: The Q&A training set generated via OpenAI.
* `spring_boot_rag_llamaparse.json`: The RAG data source parsed via Llama Parse.

### 2. Step-by-Step Execution
1.  **Token Setup:** Paste your **Ngrok Auth Token** into the variable in **Cell 2**.
2.  **Sequential Execution:** Run the cells from top to bottom:
    * *Setup -> Load Model -> Fine-Tune -> RAG Prep -> Web Server*
3.  **Access:** Click the public link (`https://....ngrok-free.app`) generated in the final cell output.

## âš™ï¸ Technical Parameters

Critical settings used to ensure stability on the T4 GPU:

| Parameter | Value | Description |
| :--- | :--- | :--- |
| `Model` | `unsloth/Meta-Llama-3.1-8B...` | Compressed version using 4-bit Quantization. |
| `MAX_SEQ_LENGTH` | `2048` | Token limit set to manage T4 VRAM usage. |
| `LoRA Rank (r)` | `16` | Parameter density trained during fine-tuning. |
| `Temperature` | `0.3` | Low creativity setting to prevent hallucinations in code generation. |

## ğŸ“‚ Appendix: Data Processing Pipeline

This project includes custom scripts used to generate the datasets from raw PDF documentation. These scripts are provided in the source code for reference.

### 1. PDF to Markdown Converter (`transformate_pdf_to_markdown.py`)
This script handles the raw data ingestion process.
* **Function:** It utilizes **LlamaParse** technology to convert complex PDF documents (like the Spring Boot Reference Guide) into structured Markdown format.
* **Why it's important:** Standard PDF parsers often break tables and layout. This script preserves semantic structure, headers, and tables, which is critical for the RAG system to understand the context.
* **Output:** Generates a clean JSON file containing document chunks.

### 2. Synthetic Data Generator (`open_ai_QA_tranformator_from_rag_data.py`)
This script prepares the training data for the Fine-Tuning process.
* **Function:** It reads the parsed RAG data and uses **OpenAI's GPT-4o-mini** model to generate high-quality "Question-Answer" pairs.
* **Methodology:** It acts as an expert instructor, creating realistic technical questions and "Best Practice" answers based on the documentation content.
* **Output:** Generates a `.jsonl` file formatted specifically for "Instruction Fine-Tuning".

---
---

<a name="-tÃ¼rkÃ§e-dokÃ¼mantasyon"></a>
# ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e DokÃ¼mantasyon

Bu proje, **Spring Boot** ekosistemi iÃ§in Ã¶zelleÅŸtirilmiÅŸ, **RAG (Retrieval-Augmented Generation)** ve **Fine-Tuning (Ä°nce Ayar)** tekniklerini birleÅŸtiren ileri seviye bir Yapay Zeka asistanÄ±dÄ±r.

**Google Colab T4 GPU** Ã¼zerinde **Unsloth** optimizasyon Ã§atÄ±sÄ± kullanÄ±larak geliÅŸtirilen sistem, **Meta-Llama-3.1-8B-Instruct** modelini temel alÄ±r. Hem dokÃ¼mantasyona dayalÄ± kesin bilgi eriÅŸimi (RAG) hem de modelin iÃ§selleÅŸtirilmiÅŸ bilgi yeteneÄŸini (Fine-Tuning) bir arada sunar.

## ğŸš€ Proje HakkÄ±nda ve GeliÅŸtirme SÃ¼reci

Bu sistem sÄ±radan bir chatbot uygulamasÄ±ndan farklÄ± olarak, ham dokÃ¼mantasyonun iÅŸlenmesiyle oluÅŸturulmuÅŸ Ã¶zel bir veri hattÄ± (pipeline) Ã¼zerine kuruludur:

1.  **Veri Ä°ÅŸleme (Llama Parse):** GeliÅŸtirme sÃ¼reci, resmi **Spring Boot PDF dokÃ¼mantasyonunun** iÅŸlenmesiyle baÅŸladÄ±. KarmaÅŸÄ±k PDF yapÄ±sÄ±nÄ± (tablolar, baÅŸlÄ±klar) anlamlÄ± metinlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in **Llama Parse** kÃ¼tÃ¼phanesi kullanÄ±ldÄ±.
2.  **Veri Seti Ãœretimi (OpenAI API):** Modelin sadece "okuyan" deÄŸil, "anlayan" bir uzmana dÃ¶nÃ¼ÅŸmesi iÃ§in ayrÄ±ÅŸtÄ±rÄ±lan dokÃ¼manlar **OpenAI API** ile iÅŸlendi. Bu aÅŸamada, yÃ¼ksek kaliteli **Soru-Cevap (Question-Answer)** Ã§iftleri Ã¼retilerek JSON formatÄ±nda bir **Fine-Tuning veri seti** oluÅŸturuldu.
3.  **Hibrit Mimari (RAG + FT):**
    * **RAG (Bilgi BankasÄ±):** AyrÄ±ÅŸtÄ±rÄ±lan iÃ§erikler, modelin anlÄ±k ve gÃ¼ncel bilgiye eriÅŸebilmesi iÃ§in vektÃ¶r tabanlÄ± bir JSON bilgi bankasÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.
    * **Fine-Tuning (UzmanlÄ±k):** Ãœretilen soru-cevap setleri ile Llama 3.1 8B modeli **Colab T4** Ã¼zerinde eÄŸitilerek, Spring Boot konseptlerine ve kodlama tarzÄ±na hakim olmasÄ± saÄŸlandÄ±.

## âš¡ Ã–zellikler

* **T4 GPU Optimizasyonu:** Unsloth ve 4-bit quantization sayesinde tÃ¼m sistem Ã¼cretsiz Colab GPU'sunda Ã§alÄ±ÅŸÄ±r.
* **AkÄ±llÄ± Ã‡eviri AjanÄ±:** TÃ¼rkÃ§e sorularÄ± arka planda teknik terminolojiye sadÄ±k kalarak Ä°ngilizceye Ã§evirir ve RAG baÅŸarÄ±sÄ±nÄ± artÄ±rÄ±r.
* **Web ArayÃ¼zÃ¼:** Syntax highlighting destekli, ChatGPT benzeri modern bir arayÃ¼z.
* **DÄ±ÅŸa AÃ§Ä±lÄ±m:** Ngrok tÃ¼nellemesi ile yerel sunucuyu internete aÃ§ar.

## ğŸ› ï¸ Kurulum ve Colab KullanÄ±mÄ±

### 1. Gerekli Dosyalar
Google Colab sol menÃ¼sÃ¼ndeki dosya yÃ¶neticisine ÅŸu iki dosyayÄ± yÃ¼kleyin:
* `spring_boot_finetune_full.jsonl`: OpenAI ile Ã¼retilmiÅŸ Soru-Cevap eÄŸitim seti.
* `spring_boot_rag_llamaparse.json`: Llama Parse ile ayrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ RAG veri kaynaÄŸÄ±.

### 2. AdÄ±m AdÄ±m Ã‡alÄ±ÅŸtÄ±rma
1.  **Token AyarÄ±:** Kodun **2. hÃ¼cresine** Ngrok Auth Token'Ä±nÄ±zÄ± yapÄ±ÅŸtÄ±rÄ±n.
2.  **SÄ±ralÄ± BaÅŸlatma:** HÃ¼creleri yukarÄ±dan aÅŸaÄŸÄ±ya sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n:
    * *Kurulum -> Model YÃ¼kleme -> EÄŸitim (Fine-Tune) -> RAG HazÄ±rlÄ±ÄŸÄ± -> Web Sunucusu*
3.  **EriÅŸim:** Son hÃ¼credeki `https://....ngrok-free.app` linkine tÄ±klayÄ±n.

## âš™ï¸ Teknik Parametreler

Sistemin T4 GPU Ã¼zerinde stabil Ã§alÄ±ÅŸmasÄ± iÃ§in kullanÄ±lan kritik ayarlar:

| Parametre | DeÄŸer | AÃ§Ä±klama |
| :--- | :--- | :--- |
| `Model` | `unsloth/Meta-Llama-3.1-8B...` | 4-bit Quantization ile sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ versiyon. |
| `MAX_SEQ_LENGTH` | `2048` | T4 belleÄŸini yÃ¶netmek iÃ§in belirlenen token sÄ±nÄ±rÄ±. |
| `LoRA Rank (r)` | `16` | Fine-tuning sÄ±rasÄ±nda eÄŸitilen parametre yoÄŸunluÄŸu. |
| `Temperature` | `0.3` | Kod Ã¼retiminde halÃ¼sinasyonu Ã¶nlemek iÃ§in dÃ¼ÅŸÃ¼k yaratÄ±cÄ±lÄ±k ayarÄ±. |

## ğŸ“‚ Ek: Veri Ä°ÅŸleme HattÄ± (AÃ§Ä±klama)

Bu projenin veri setleri, ham PDF dokÃ¼manlarÄ±ndan Ã¶zel scriptler kullanÄ±larak Ã¼retilmiÅŸtir. Proje kaynak kodlarÄ±nda bulunan bu scriptlerin iÅŸlevleri ÅŸÃ¶yledir:

### 1. PDF'ten Markdown'a DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ (`transformate_pdf_to_markdown.py`)
Bu script, ham veri giriÅŸini saÄŸlar.
* **Ä°ÅŸlevi:** KarmaÅŸÄ±k yapÄ±daki teknik PDF dokÃ¼manlarÄ±nÄ± (Tablolar, listeler vb.) **LlamaParse** teknolojisi ile anlamlÄ± Markdown formatÄ±na Ã§evirir.
* **Ã–nemi:** Standart PDF okuyucular tablolarÄ± bozarak verinin anlamÄ±nÄ± yitirmesine sebep olur. Bu araÃ§, RAG sisteminin doÄŸru baÄŸlamÄ± yakalamasÄ± iÃ§in kritik olan yapÄ±sal bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ korur.
* **Ã‡Ä±ktÄ±:** RAG sistemi iÃ§in temizlenmiÅŸ JSON verisi Ã¼retir.

### 2. Sentetik Veri Ãœretici (`open_ai_QA_tranformator_from_rag_data.py`)
Bu script, eÄŸitim (Fine-Tuning) verisini hazÄ±rlar.
* **Ä°ÅŸlevi:** AyrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ metin verilerini okur ve **OpenAI GPT-4o-mini** modelini kullanarak "Soru-Cevap" Ã§iftleri oluÅŸturur.
* **YÃ¶ntemi:** Bir "Uzman EÄŸitmen" rolÃ¼ne bÃ¼rÃ¼nerek, dokÃ¼mandaki bilgilerden gerÃ§ekÃ§i yazÄ±lÄ±mcÄ± sorularÄ± ve "Best Practice" iÃ§eren cevaplar tÃ¼retir.
* **Ã‡Ä±ktÄ±:** Modelin eÄŸitimi iÃ§in hazÄ±r `.jsonl` formatÄ±nda veri seti Ã¼retir.
