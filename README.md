# ğŸƒ Spring Boot AI Assistant (Hybrid: RAG + Fine-Tuning)

This project is an advanced AI assistant specialized for the **Spring Boot** ecosystem, combining **RAG (Retrieval-Augmented Generation)** and **Fine-Tuning** techniques.

Built to run on **Google Colab T4 GPU** using the **Unsloth** optimization framework, it utilizes the **Meta-Llama-3.1-8B-Instruct** model. It delivers both precise information retrieval based on documentation (RAG) and internalized domain expertise (Fine-Tuning).

---

## ğŸš€ About the Project & Development Process

Unlike standard chatbots, this system is built on a custom data pipeline derived from raw documentation processing:

### 1. ğŸ“„ Data Processing (Llama Parse)
The development process began by parsing the official **Spring Boot PDF documentation**. The **Llama Parse** library was used to transform complex PDF structures into machine-readable, structured text suitable for processing.

### 2. ğŸ§  Dataset Generation (OpenAI API)
To transform the model from a simple "reader" into an "expert," the parsed documents were processed via the **OpenAI API**. High-quality **Question-Answer pairs** were generated to create a structured JSON **Fine-Tuning dataset**.

### 3. ğŸ¯ Hybrid Architecture (RAG + FT)
* **RAG (Knowledge Base):** The parsed content was converted into a vector-based JSON knowledge base to allow the model to access real-time, up-to-date information.
* **Fine-Tuning (Expertise):** Using the generated Q&A pairs, the Llama 3.1 8B model was fine-tuned on **Colab T4** to deeply understand Spring Boot concepts and coding standards.

---

## âš¡ Features

* **T4 GPU Optimization:** Thanks to Unsloth and 4-bit quantization, the entire system runs smoothly on the free Colab T4 GPU.
* **Smart Translation Agent:** Automatically translates non-English queries into English in the background to improve RAG retrieval accuracy while preserving technical terminology.
* **Web Interface:** Features a modern, ChatGPT-like interface with syntax highlighting.
* **Public Access:** Exposes the local Colab server to the internet via Ngrok tunneling.

---

## ğŸ”® Future Plans (Roadmap)

The project is currently under active development. Future goals include:
* ğŸ“š Integrating more extensive official documentation.
* ğŸ’» Adding real-world scenarios and code patterns from GitHub repositories to the dataset.
* ğŸ“ˆ Increasing the dataset volume and further improving the model's accuracy.

---

## ğŸ› ï¸ Installation & Usage on Colab

### Required Files
Upload the following two files to the file manager in the left sidebar:
1.  `spring_boot_finetune_full.jsonl`: The Q&A training set generated via OpenAI.
2.  `spring_boot_rag_llamaparse.json`: The RAG data source parsed via Llama Parse.

### Step-by-Step Execution
1.  **Token Setup:** Paste your **Ngrok Auth Token** into the variable in Cell 2.
2.  **Sequential Execution:** Run the cells from top to bottom:
    * *Setup -> Load Model -> Fine-Tune -> RAG Prep -> Web Server*
3.  **Access:** Click the public link (`https://....ngrok-free.app`) generated in the final cell output.

---

## âš™ï¸ Technical Parameters

Critical settings used to ensure stability on the T4 GPU:

| Parameter | Value | Description |
| :--- | :--- | :--- |
| `Model` | `unsloth/Meta-Llama-3.1-8B...` | Compressed version using 4-bit Quantization. |
| `MAX_SEQ_LENGTH` | `2048` | Token limit set to manage T4 VRAM usage. |
| `LoRA Rank (r)` | `16` | Parameter density trained during fine-tuning. |
| `Temperature` | `0.3` | Low creativity setting to prevent hallucinations in code generation. |

---



# ğŸƒ Spring Boot AI Assistant (Hybrid: RAG + Fine-Tuning)

Bu proje, **Spring Boot** ekosistemi iÃ§in Ã¶zelleÅŸtirilmiÅŸ, **RAG (Retrieval-Augmented Generation)** ve **Fine-Tuning (Ä°nce Ayar)** tekniklerini birleÅŸtiren ileri seviye bir Yapay Zeka asistanÄ±dÄ±r.

**Google Colab T4 GPU** Ã¼zerinde **Unsloth** optimizasyon Ã§atÄ±sÄ± kullanÄ±larak geliÅŸtirilen sistem, **Meta-Llama-3.1-8B-Instruct** modelini temel alÄ±r. Hem dokÃ¼mantasyona dayalÄ± kesin bilgi eriÅŸimi (RAG) hem de modelin iÃ§selleÅŸtirilmiÅŸ bilgi yeteneÄŸini (Fine-Tuning) bir arada sunar.

---

## ğŸš€ Proje HakkÄ±nda ve GeliÅŸtirme SÃ¼reci

Bu sistem sÄ±radan bir chatbot uygulamasÄ±ndan farklÄ± olarak, ham dokÃ¼mantasyonun iÅŸlenmesiyle oluÅŸturulmuÅŸ Ã¶zel bir veri hattÄ± (pipeline) Ã¼zerine kuruludur:

### 1. ğŸ“„ Veri Ä°ÅŸleme (Llama Parse)
GeliÅŸtirme sÃ¼reci, resmi **Spring Boot PDF dokÃ¼mantasyonunun** iÅŸlenmesiyle baÅŸladÄ±. KarmaÅŸÄ±k PDF yapÄ±sÄ±nÄ± anlamlÄ± metinlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in **Llama Parse** kÃ¼tÃ¼phanesi kullanÄ±ldÄ±. Bu iÅŸlem sonucunda ham veri, makine tarafÄ±ndan okunabilir yapÄ±sal bir formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.

### 2. ğŸ§  Veri Seti Ãœretimi (OpenAI API)
Modelin sadece "okuyan" deÄŸil, "anlayan" bir uzmana dÃ¶nÃ¼ÅŸmesi iÃ§in ayrÄ±ÅŸtÄ±rÄ±lan dokÃ¼manlar **OpenAI API** ile iÅŸlendi. Bu aÅŸamada, yÃ¼ksek kaliteli **Soru-Cevap (Question-Answer)** Ã§iftleri Ã¼retilerek JSON formatÄ±nda bir **Fine-Tuning veri seti** oluÅŸturuldu.

### 3. ğŸ¯ Hibrit Mimari (RAG + FT)
* **RAG (Bilgi BankasÄ±):** AyrÄ±ÅŸtÄ±rÄ±lan iÃ§erikler, modelin anlÄ±k ve gÃ¼ncel bilgiye eriÅŸebilmesi iÃ§in vektÃ¶r tabanlÄ± bir JSON bilgi bankasÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.
* **Fine-Tuning (UzmanlÄ±k):** Ãœretilen soru-cevap setleri ile Llama 3.1 8B modeli **Colab T4** Ã¼zerinde eÄŸitilerek, Spring Boot konseptlerine ve kodlama tarzÄ±na hakim olmasÄ± saÄŸlandÄ±.

---

## âš¡ Ã–zellikler

* **T4 GPU Optimizasyonu:** Unsloth ve 4-bit quantization sayesinde tÃ¼m sistem Ã¼cretsiz Colab GPU'sunda Ã§alÄ±ÅŸÄ±r.
* **AkÄ±llÄ± Ã‡eviri AjanÄ±:** TÃ¼rkÃ§e sorularÄ± arka planda teknik terminolojiye sadÄ±k kalarak Ä°ngilizceye Ã§evirir ve RAG baÅŸarÄ±sÄ±nÄ± artÄ±rÄ±r.
* **Web ArayÃ¼zÃ¼:** Syntax highlighting destekli, ChatGPT benzeri modern bir arayÃ¼z.
* **DÄ±ÅŸa AÃ§Ä±lÄ±m:** Ngrok tÃ¼nellemesi ile yerel sunucuyu internete aÃ§ar.

---

## ğŸ”® Gelecek PlanlarÄ± (Roadmap)

Proje ÅŸu anda aktif geliÅŸtirme aÅŸamasÄ±ndadÄ±r. Ä°lerleyen dÃ¶nemler iÃ§in hedeflenen geliÅŸtirmeler:
* ğŸ“š Daha fazla resmi dokÃ¼mantasyonun entegrasyonu.
* ğŸ’» GerÃ§ek dÃ¼nya senaryolarÄ±nÄ± kapsayan GitHub repolarÄ±nÄ±n veri setine eklenmesi.
* ğŸ“ˆ Veri setinin hacminin artÄ±rÄ±lmasÄ± ve modelin doÄŸruluk oranÄ±nÄ±n iyileÅŸtirilmesi.

---

## ğŸ› ï¸ Kurulum ve Colab KullanÄ±mÄ±

### Gerekli Dosyalar
Sol menÃ¼deki dosya yÃ¶neticisine ÅŸu iki dosyayÄ± yÃ¼kleyin:
1.  `spring_boot_finetune_full.jsonl`: OpenAI ile Ã¼retilmiÅŸ Soru-Cevap eÄŸitim seti.
2.  `spring_boot_rag_llamaparse.json`: Llama Parse ile ayrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ RAG veri kaynaÄŸÄ±.

### AdÄ±m AdÄ±m Ã‡alÄ±ÅŸtÄ±rma
1.  **Token AyarÄ±:** Kodun 2. hÃ¼cresine **Ngrok Auth Token**'Ä±nÄ±zÄ± yapÄ±ÅŸtÄ±rÄ±n.
2.  **SÄ±ralÄ± BaÅŸlatma:** HÃ¼creleri yukarÄ±dan aÅŸaÄŸÄ±ya sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n.
    * *Kurulum -> Model YÃ¼kleme -> EÄŸitim (Fine-Tune) -> RAG HazÄ±rlÄ±ÄŸÄ± -> Web Sunucusu*
3.  **EriÅŸim:** Son hÃ¼credeki `https://....ngrok-free.app` linkine tÄ±klayÄ±n.

---

## âš™ï¸ Teknik Parametreler

Sistemin T4 GPU Ã¼zerinde stabil Ã§alÄ±ÅŸmasÄ± iÃ§in kullanÄ±lan kritik ayarlar:

| Parametre | DeÄŸer | AÃ§Ä±klama |
| :--- | :--- | :--- |
| `Model` | `unsloth/Meta-Llama-3.1-8B...` | 4-bit Quantization ile sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ versiyon. |
| `MAX_SEQ_LENGTH` | `2048` | T4 belleÄŸini yÃ¶netmek iÃ§in belirlenen token sÄ±nÄ±rÄ±. |
| `LoRA Rank (r)` | `16` | Fine-tuning sÄ±rasÄ±nda eÄŸitilen parametre yoÄŸunluÄŸu. |
| `Temperature` | `0.3` | Kod Ã¼retiminde halÃ¼sinasyonu Ã¶nlemek iÃ§in dÃ¼ÅŸÃ¼k yaratÄ±cÄ±lÄ±k ayarÄ±. |

---





