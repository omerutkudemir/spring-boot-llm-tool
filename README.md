# üçÉ Spring Boot AI Assistant (Hybrid: RAG + Fine-Tuning)

Bu proje, **Spring Boot** ekosistemi i√ßin √∂zelle≈ütirilmi≈ü, **RAG (Retrieval-Augmented Generation)** ve **Fine-Tuning (ƒ∞nce Ayar)** tekniklerini birle≈ütiren ileri seviye bir Yapay Zeka asistanƒ±dƒ±r.

**Google Colab T4 GPU** √ºzerinde **Unsloth** optimizasyon √ßatƒ±sƒ± kullanƒ±larak geli≈ütirilen sistem, **Meta-Llama-3.1-8B-Instruct** modelini temel alƒ±r. Hem dok√ºmantasyona dayalƒ± kesin bilgi eri≈üimi (RAG) hem de modelin i√ßselle≈ütirilmi≈ü bilgi yeteneƒüini (Fine-Tuning) bir arada sunar.

---

## üöÄ Proje Hakkƒ±nda ve Geli≈ütirme S√ºreci

Bu sistem sƒ±radan bir chatbot uygulamasƒ±ndan farklƒ± olarak, ham dok√ºmantasyonun i≈ülenmesiyle olu≈üturulmu≈ü √∂zel bir veri hattƒ± (pipeline) √ºzerine kuruludur:

### 1. üìÑ Veri ƒ∞≈üleme (Llama Parse)
Geli≈ütirme s√ºreci, resmi **Spring Boot PDF dok√ºmantasyonunun** i≈ülenmesiyle ba≈üladƒ±. Karma≈üƒ±k PDF yapƒ±sƒ±nƒ± anlamlƒ± metinlere d√∂n√º≈üt√ºrmek i√ßin **Llama Parse** k√ºt√ºphanesi kullanƒ±ldƒ±. Bu i≈ülem sonucunda ham veri, makine tarafƒ±ndan okunabilir yapƒ±sal bir formata d√∂n√º≈üt√ºr√ºld√º.

### 2. üß† Veri Seti √úretimi (OpenAI API)
Modelin sadece "okuyan" deƒüil, "anlayan" bir uzmana d√∂n√º≈ümesi i√ßin ayrƒ±≈ütƒ±rƒ±lan dok√ºmanlar **OpenAI API** ile i≈ülendi. Bu a≈üamada, y√ºksek kaliteli **Soru-Cevap (Question-Answer)** √ßiftleri √ºretilerek JSON formatƒ±nda bir **Fine-Tuning veri seti** olu≈üturuldu.

### 3. üéØ Hibrit Mimari (RAG + FT)
* **RAG (Bilgi Bankasƒ±):** Ayrƒ±≈ütƒ±rƒ±lan i√ßerikler, modelin anlƒ±k ve g√ºncel bilgiye eri≈üebilmesi i√ßin vekt√∂r tabanlƒ± bir JSON bilgi bankasƒ±na d√∂n√º≈üt√ºr√ºld√º.
* **Fine-Tuning (Uzmanlƒ±k):** √úretilen soru-cevap setleri ile Llama 3.1 8B modeli **Colab T4** √ºzerinde eƒüitilerek, Spring Boot konseptlerine ve kodlama tarzƒ±na hakim olmasƒ± saƒülandƒ±.

---

## ‚ö° √ñzellikler

* **T4 GPU Optimizasyonu:** Unsloth ve 4-bit quantization sayesinde t√ºm sistem √ºcretsiz Colab GPU'sunda √ßalƒ±≈üƒ±r.
* **Akƒ±llƒ± √áeviri Ajanƒ±:** T√ºrk√ße sorularƒ± arka planda teknik terminolojiye sadƒ±k kalarak ƒ∞ngilizceye √ßevirir ve RAG ba≈üarƒ±sƒ±nƒ± artƒ±rƒ±r.
* **Web Aray√ºz√º:** Syntax highlighting destekli, ChatGPT benzeri modern bir aray√ºz.
* **Dƒ±≈üa A√ßƒ±lƒ±m:** Ngrok t√ºnellemesi ile yerel sunucuyu internete a√ßar.

---

## üîÆ Gelecek Planlarƒ± (Roadmap)

Proje ≈üu anda aktif geli≈ütirme a≈üamasƒ±ndadƒ±r. ƒ∞lerleyen d√∂nemler i√ßin hedeflenen geli≈ütirmeler:
* üìö Daha fazla resmi dok√ºmantasyonun entegrasyonu.
* üíª Ger√ßek d√ºnya senaryolarƒ±nƒ± kapsayan GitHub repolarƒ±nƒ±n veri setine eklenmesi.
* üìà Veri setinin hacminin artƒ±rƒ±lmasƒ± ve modelin doƒüruluk oranƒ±nƒ±n iyile≈ütirilmesi.

---

## üõ†Ô∏è Kurulum ve Colab Kullanƒ±mƒ±

### Gerekli Dosyalar
Sol men√ºdeki dosya y√∂neticisine ≈üu iki dosyayƒ± y√ºkleyin:
1.  `spring_boot_finetune_full.jsonl`: OpenAI ile √ºretilmi≈ü Soru-Cevap eƒüitim seti.
2.  `spring_boot_rag_llamaparse.json`: Llama Parse ile ayrƒ±≈ütƒ±rƒ±lmƒ±≈ü RAG veri kaynaƒüƒ±.

### Adƒ±m Adƒ±m √áalƒ±≈ütƒ±rma
1.  **Token Ayarƒ±:** Kodun 2. h√ºcresine **Ngrok Auth Token**'ƒ±nƒ±zƒ± yapƒ±≈ütƒ±rƒ±n.
2.  **Sƒ±ralƒ± Ba≈ülatma:** H√ºcreleri yukarƒ±dan a≈üaƒüƒ±ya sƒ±rasƒ±yla √ßalƒ±≈ütƒ±rƒ±n.
    * *Kurulum -> Model Y√ºkleme -> Eƒüitim (Fine-Tune) -> RAG Hazƒ±rlƒ±ƒüƒ± -> Web Sunucusu*
3.  **Eri≈üim:** Son h√ºcredeki `https://....ngrok-free.app` linkine tƒ±klayƒ±n.

---

## ‚öôÔ∏è Teknik Parametreler

Sistemin T4 GPU √ºzerinde stabil √ßalƒ±≈ümasƒ± i√ßin kullanƒ±lan kritik ayarlar:

| Parametre | Deƒüer | A√ßƒ±klama |
| :--- | :--- | :--- |
| `Model` | `unsloth/Meta-Llama-3.1-8B...` | 4-bit Quantization ile sƒ±kƒ±≈ütƒ±rƒ±lmƒ±≈ü versiyon. |
| `MAX_SEQ_LENGTH` | `2048` | T4 belleƒüini y√∂netmek i√ßin belirlenen token sƒ±nƒ±rƒ±. |
| `LoRA Rank (r)` | `16` | Fine-tuning sƒ±rasƒ±nda eƒüitilen parametre yoƒüunluƒüu. |
| `Temperature` | `0.3` | Kod √ºretiminde hal√ºsinasyonu √∂nlemek i√ßin d√º≈ü√ºk yaratƒ±cƒ±lƒ±k ayarƒ±. |

---



# üçÉ Spring Boot AI Assistant (Hybrid: RAG + Fine-Tuning)

This project is an advanced AI assistant specialized for the **Spring Boot** ecosystem, combining **RAG (Retrieval-Augmented Generation)** and **Fine-Tuning** techniques.

Built to run on **Google Colab T4 GPU** using the **Unsloth** optimization framework, it utilizes the **Meta-Llama-3.1-8B-Instruct** model. It delivers both precise information retrieval based on documentation (RAG) and internalized domain expertise (Fine-Tuning).

---

## üöÄ About the Project & Development Process

Unlike standard chatbots, this system is built on a custom data pipeline derived from raw documentation processing:

### 1. üìÑ Data Processing (Llama Parse)
The development process began by parsing the official **Spring Boot PDF documentation**. The **Llama Parse** library was used to transform complex PDF structures into machine-readable, structured text suitable for processing.

### 2. üß† Dataset Generation (OpenAI API)
To transform the model from a simple "reader" into an "expert," the parsed documents were processed via the **OpenAI API**. High-quality **Question-Answer pairs** were generated to create a structured JSON **Fine-Tuning dataset**.

### 3. üéØ Hybrid Architecture (RAG + FT)
* **RAG (Knowledge Base):** The parsed content was converted into a vector-based JSON knowledge base to allow the model to access real-time, up-to-date information.
* **Fine-Tuning (Expertise):** Using the generated Q&A pairs, the Llama 3.1 8B model was fine-tuned on **Colab T4** to deeply understand Spring Boot concepts and coding standards.

---

## ‚ö° Features

* **T4 GPU Optimization:** Thanks to Unsloth and 4-bit quantization, the entire system runs smoothly on the free Colab T4 GPU.
* **Smart Translation Agent:** Automatically translates non-English queries into English in the background to improve RAG retrieval accuracy while preserving technical terminology.
* **Web Interface:** Features a modern, ChatGPT-like interface with syntax highlighting.
* **Public Access:** Exposes the local Colab server to the internet via Ngrok tunneling.

---

## üîÆ Future Plans (Roadmap)

The project is currently under active development. Future goals include:
* üìö Integrating more extensive official documentation.
* üíª Adding real-world scenarios and code patterns from GitHub repositories to the dataset.
* üìà Increasing the dataset volume and further improving the model's accuracy.

---

## üõ†Ô∏è Installation & Usage on Colab

### Required Files
Upload the following two files to the file manager in the left sidebar:
1.  `spring_boot_finetune_full.jsonl`: The Q&A training set generated via OpenAI.
2.  `spring_boot_rag_llamaparse.json`: The RAG data source parsed via Llama Parse.

### Step-by-Step Execution
1.  **Token Setup:** Paste your **Ngrok Auth Token** into the variable in Cell 2.
2.  **Sequential Execution:** Run the cells from top to bottom:
    * *Setup -> Load Model -> Fine-Tune -> RAG Prep -> Web Server*
3.  **Access:** Click the public link (`https://....ngrok-free.app`) generated in the final cell output.

---

## ‚öôÔ∏è Technical Parameters

Critical settings used to ensure stability on the T4 GPU:

| Parameter | Value | Description |
| :--- | :--- | :--- |
| `Model` | `unsloth/Meta-Llama-3.1-8B...` | Compressed version using 4-bit Quantization. |
| `MAX_SEQ_LENGTH` | `2048` | Token limit set to manage T4 VRAM usage. |
| `LoRA Rank (r)` | `16` | Parameter density trained during fine-tuning. |
| `Temperature` | `0.3` | Low creativity setting to prevent hallucinations in code generation. |

---


