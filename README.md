# ğŸƒ Spring Boot AI Assistant (Llama 3.1 + RAG + Fine-Tuning) on Colab T4

Bu proje, **Google Colab (Free Tier)** Ã¼zerinde sunulan **Tesla T4 GPU** ile Ã§alÄ±ÅŸacak ÅŸekilde Ã¶zel olarak optimize edilmiÅŸtir.

**Unsloth** kÃ¼tÃ¼phanesi sayesinde, normalde Ã§ok daha gÃ¼Ã§lÃ¼ donanÄ±m gerektiren **Llama 3.1 8B** modeli, Colab'Ä±n Ã¼cretsiz T4 GPU'sunda hem eÄŸitilebilir (Fine-Tuning) hem de RAG (Retrieval-Augmented Generation) sistemiyle birleÅŸtirilerek Ã§alÄ±ÅŸtÄ±rÄ±labilir.

---

## ğŸš€ Ã–zellikler

* **âš¡ Colab T4 Optimizasyonu:** Unsloth teknolojisi ile model, T4 GPU'nun 16GB VRAM'ine sÄ±ÄŸacak ÅŸekilde (4-bit quantization) sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.
* **ğŸ§  Fine-Tuning (SFT):** Model, Spring Boot kodlama standartlarÄ±nÄ± Ã¶ÄŸrenmek iÃ§in Ã§alÄ±ÅŸma anÄ±nda eÄŸitilir.
* **ğŸ“š RAG Mimarisi:** GÃ¼ncel Spring Boot dokÃ¼mantasyonunu vektÃ¶r veritabanÄ±nda (FAISS) tutar ve halÃ¼sinasyonu Ã¶nler.
* **translator-agent:** TÃ¼rkÃ§e sorulan teknik sorularÄ±, vektÃ¶r arama baÅŸarÄ±sÄ±nÄ± artÄ±rmak iÃ§in arka planda Ä°ngilizceye Ã§evirir.
* **ğŸŒ Web ArayÃ¼zÃ¼:** Colab iÃ§inde Ã§alÄ±ÅŸan sistemi, dÄ±ÅŸ dÃ¼nyaya aÃ§an modern bir Chat arayÃ¼zÃ¼ sunar.
* **ğŸ”— Ngrok TÃ¼nelleme:** Colab'Ä±n local portunu internete aÃ§arak tarayÄ±cÄ±dan eriÅŸim saÄŸlar.

---

## ğŸ› ï¸ Kurulum ve Ortam HazÄ±rlÄ±ÄŸÄ±

Bu projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in Google Colab Ã¼zerinde GPU hÄ±zlandÄ±rmayÄ± aktif etmeniz yeterlidir.

### 1. Colab AyarlarÄ±
Colab menÃ¼sÃ¼nden ÅŸu adÄ±mlarÄ± izleyin:
1.  **Ã‡alÄ±ÅŸma ZamanÄ± (Runtime)** > **Ã‡alÄ±ÅŸma ZamanÄ± TÃ¼rÃ¼nÃ¼ DeÄŸiÅŸtir (Change runtime type)**
2.  **DonanÄ±m HÄ±zlandÄ±rÄ±cÄ± (Hardware accelerator):** `T4 GPU` seÃ§in.
3.  **Kaydet** diyerek onaylayÄ±n.

### 2. Gerekli Dosyalar
Kodun hatasÄ±z Ã§alÄ±ÅŸmasÄ± iÃ§in sol menÃ¼deki **Dosyalar** kÄ±smÄ±na ÅŸu iki dosyayÄ± sÃ¼rÃ¼kleyip bÄ±rakÄ±n:
* `spring_boot_finetune_full.jsonl`: Fine-tuning iÃ§in soru-cevap Ã§iftleri.
* `spring_boot_rag_llamaparse.json`: RAG sistemi iÃ§in ham dokÃ¼mantasyon verisi.

---

## ğŸ§© Sistem Mimarisi ve Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±

Sistem, T4 GPU sÄ±nÄ±rlarÄ± iÃ§inde kalacak ÅŸekilde 5 aÅŸamalÄ± bir mimariye sahiptir:

### 1. Model YÃ¼kleme (4-bit Quantization)
`unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit` modeli yÃ¼klenir.
* **Neden 4-bit?** Normalde 8 milyar parametreli bir model yaklaÅŸÄ±k 16GB+ VRAM gerektirir. 4-bit yÃ¼kleme ile bu gereksinim dÃ¼ÅŸÃ¼rÃ¼lerek T4 GPU Ã¼zerinde Ã§alÄ±ÅŸmasÄ± saÄŸlanÄ±r.

### 2. LoRA AdaptÃ¶rleri (PEFT)
Modelin tamamÄ± eÄŸitilmez (bu T4'Ã¼ Ã§Ã¶kertirdi). Bunun yerine **LoRA (Low-Rank Adaptation)** tekniÄŸi ile modelin sadece %1-2'lik kÄ±smÄ±na "yama" yapÄ±lÄ±r.
* **Target Modules:** `["q_proj", "k_proj", ...]` Modelin dikkat mekanizmalarÄ± eÄŸitilerek Spring Boot bilgisi aÅŸÄ±lanÄ±r.

### 3. Veri Temizleme ve RAG HazÄ±rlÄ±ÄŸÄ±
YÃ¼klenen ham JSON verisi, kod iÃ§indeki temizleyici (cleaner) script ile iÅŸlenir:
* GÃ¼rÃ¼ltÃ¼lÃ¼ veriler (Ä°Ã§indekiler, Lisanslar) silinir.
* Veriler `sentence-transformers` ile vektÃ¶rlere Ã§evrilip RAM Ã¼zerinde Ã§alÄ±ÅŸan **FAISS** veritabanÄ±na kaydedilir.

### 4. Fine-Tuning (EÄŸitim)
Model, yÃ¼klediÄŸiniz `jsonl` verisi ile hÄ±zlÄ± bir eÄŸitime tabi tutulur.
* **SÃ¼re:** YaklaÅŸÄ±k 5-10 dakika (Veri boyutuna gÃ¶re deÄŸiÅŸir).
* **SonuÃ§:** Model artÄ±k Spring Boot 3.0+ kodlama standartlarÄ±na daha aÅŸina hale gelir.

### 5. Flask API ve Chat AkÄ±ÅŸÄ±
KullanÄ±cÄ± arayÃ¼zÃ¼ Ã¼zerinden gelen sorular ÅŸu akÄ±ÅŸla iÅŸlenir:
1.  **Ã‡eviri:** Soru arka planda Ä°ngilizceye Ã§evrilir (Daha iyi dokÃ¼man bulmak iÃ§in).
2.  **RAG:** FAISS veritabanÄ±ndan en alakalÄ± 3 kod parÃ§asÄ± Ã§ekilir.
3.  **Ãœretim:** Bulunan parÃ§alar ve kullanÄ±cÄ±nÄ±n TÃ¼rkÃ§e sorusu modele verilir.
4.  **Cevap:** Model, RAG bilgisini kullanarak Spring Boot 3.2 uyumlu cevap Ã¼retir.

---

## âš™ï¸ Ã–nemli Parametreler

Kod iÃ§erisindeki bu parametreler T4 GPU performansÄ± iÃ§in kritiktir:

| Parametre | DeÄŸer | AÃ§Ä±klama |
| :--- | :--- | :--- |
| `MAX_SEQ_LENGTH` | `2048` | T4 belleÄŸini aÅŸmamak iÃ§in gÃ¼venli sÄ±nÄ±rdÄ±r. Daha fazla artÄ±rÄ±lÄ±rsa "Out of Memory" hatasÄ± alÄ±nabilir. |
| `load_in_4bit` | `True` | T4 GPU'da Ã§alÄ±ÅŸabilmesi iÃ§in zorunludur. |
| `per_device_train_batch_size` | `2` | EÄŸitim sÄ±rasÄ±nda aynÄ± anda iÅŸlenen veri sayÄ±sÄ±. T4 iÃ§in 2 idealdir. |
| `gradient_accumulation_steps` | `4` | KÃ¼Ã§Ã¼k batch size aÃ§Ä±ÄŸÄ±nÄ± kapatmak iÃ§in gradyanlar biriktirilir. |
| `temperature` | `0.3` | Modelin yaratÄ±cÄ±lÄ±k seviyesi. Kod Ã¼retimi iÃ§in dÃ¼ÅŸÃ¼k tutulmuÅŸtur. |

---

## ğŸ–¥ï¸ AdÄ±m AdÄ±m Ã‡alÄ±ÅŸtÄ±rma KÄ±lavuzu

1.  **Token Girin:**
    Kodun 2. hÃ¼cresindeki `NGROK_AUTH_TOKEN` alanÄ±na Ngrok'tan aldÄ±ÄŸÄ±nÄ±z Ã¼cretsiz token'Ä± yapÄ±ÅŸtÄ±rÄ±n.

2.  **HÃ¼creleri Ã‡alÄ±ÅŸtÄ±rÄ±n:**
    YukarÄ±dan aÅŸaÄŸÄ±ya doÄŸru `Play` (â–¶) butonlarÄ±na basarak ilerleyin.
    * *HÃ¼cre 1:* Gerekli kÃ¼tÃ¼phaneleri kurar (Unsloth, LangChain vb.).
    * *HÃ¼cre 2:* Modeli T4 GPU'ya yÃ¼kler.
    * *HÃ¼cre 3:* Modeli eÄŸiter (Fine-Tune).
    * *HÃ¼cre 4:* DokÃ¼manlarÄ± temizler ve veritabanÄ±nÄ± kurar.
    * *HÃ¼cre 5:* Web sunucusunu baÅŸlatÄ±r.

3.  **Sisteme EriÅŸim:**
    En son hÃ¼cre Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda ekrana gelen `ğŸ‘‰ ArayÃ¼ze Gitmek Ä°Ã§in TÄ±kla: https://....ngrok-free.app` linkine tÄ±klayÄ±n.

---

## âš ï¸ Ä°puÃ§larÄ±

* **Oturum SÃ¼resi:** Google Colab Ã¼cretsiz sÃ¼rÃ¼mÃ¼ tarayÄ±cÄ± sekmesi kapandÄ±ÄŸÄ±nda veya belirli bir sÃ¼re iÅŸlem yapÄ±lmadÄ±ÄŸÄ±nda oturumu sonlandÄ±rabilir.
* **Ä°lk YanÄ±t:** Model ilk soruda "soÄŸuk baÅŸlangÄ±Ã§" nedeniyle 10-20 saniye bekletebilir, sonraki yanÄ±tlar hÄ±zlanacaktÄ±r.
* **Disk AlanÄ±:** Unsloth kÃ¼tÃ¼phanesi disk alanÄ±nÄ± verimli kullanÄ±r ancak Drive baÄŸlantÄ±sÄ± yaparsanÄ±z modelleri oraya da yedekleyebilirsiniz.

---

## ğŸ“ Lisans
Bu proje eÄŸitim ve deneme amaÃ§lÄ±dÄ±r. Llama 3.1 modeli Meta lisansÄ±na tabidir.
